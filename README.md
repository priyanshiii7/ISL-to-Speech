# Indian Sign Language - to - Speech Converter: Real-Time Sign Language Interpreter

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg)](https://opencv.org/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-Latest-orange.svg)](https://mediapipe.dev/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-ready machine learning system that bridges communication gaps by translating Indian Sign Language (ISL) gestures into spoken words in real-time. Built with computer vision and deep learning technologies to create an accessible communication tool for the hearing and speech-impaired community.


## ðŸŽ¯ Project Highlights

- **Real-time Performance**: Achieves <100ms latency for gesture recognition and speech synthesis
- **Two-Hand Support**: Recognizes complex ISL gestures requiring both hands simultaneously
- **Robust Detection**: Utilizes MediaPipe's 21-landmark hand tracking for accurate gesture identification
- **Scalable Architecture**: Modular design supporting easy addition of new gestures and languages
- **Production-Ready**: Includes data collection, training pipeline, and inference modules

## ðŸš€ Key Features

### Core Functionality
- **Live Gesture Recognition**: Webcam-based real-time ISL gesture detection
- **Text-to-Speech Conversion**: Instant audio feedback using Python's text-to-speech engine
- **Multi-Gesture Support**: Extensible framework for training on custom gesture datasets
- **Visual Feedback**: On-screen display of recognized gestures and confidence scores

### Technical Implementation
- **Hand Landmark Detection**: 21-point hand skeleton tracking via MediaPipe
- **Feature Engineering**: Geometric feature extraction from hand coordinates
- **Machine Learning Pipeline**: Complete workflow from data collection to deployment
- **Computer Vision**: OpenCV-powered image processing and real-time video analysis

## ðŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|-------------|
| **ML/AI** | scikit-learn, MediaPipe Hands |
| **Computer Vision** | OpenCV, NumPy |
| **Audio Processing** | pyttsx3 (Text-to-Speech) |
| **Language** | Python 3.8+ |
| **Data Handling** | pickle, pandas |

## ðŸ“‹ Installation

### Prerequisites
```bash
Python 3.8 or higher
Webcam/Camera access
```

### Quick Start
```bash
# Clone the repository
git clone https://github.com/priyanshiii7/ISL-to-Speech.git
cd ISL-to-Speech

# Install dependencies
pip install -r requirements.txt

# Run the application
python inference_classifier.py
```

## Project Structure

```
ISL-to-Speech/
â”œâ”€â”€ collect_imgs.py          # Data collection module for training gestures
â”œâ”€â”€ create_database.py        # Feature extraction and dataset preparation
â”œâ”€â”€ train_classifier.py       # Model training pipeline
â”œâ”€â”€ inference_classifier.py   # Real-time inference and speech synthesis
â”œâ”€â”€ data.pickle              # Serialized training dataset
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

##  How It Works

### 1. **Data Collection** (`collect_imgs.py`)
Captures gesture samples via webcam for building custom training datasets.

### 2. **Feature Extraction** (`create_database.py`)
- Detects hand landmarks using MediaPipe
- Extracts geometric features (distances, angles, ratios)
- Normalizes and stores features in pickle format

### 3. **Model Training** (`train_classifier.py`)
- Trains classifier on extracted features
- Supports various ML algorithms (can be extended to CNN/RNN)
- Saves trained model for inference

### 4. **Real-Time Inference** (`inference_classifier.py`)
- Captures live video feed
- Processes frames for hand detection
- Classifies gestures and converts to speech
- Displays results with visual feedback

## Use Cases

- **Education**: Assist in teaching ISL to students and educators
- **Healthcare**: Enable communication in medical facilities
- **Public Services**: Improve accessibility in government offices and transportation
- **Enterprise**: Workplace inclusion tools for diverse teams

## Future Enhancements

- [ ] Deep Learning Integration (CNN/LSTM for sequential gestures)
- [ ] Sentence Formation & Grammar Rules
- [ ] Multi-language Support (ASL, BSL, etc.)
- [ ] Mobile Application Development
- [ ] Cloud-based Model Deployment
- [ ] Larger Gesture Vocabulary (100+ signs)
- [ ] User Authentication & Personalization

**Made with â¤ï¸ to make communication accessible for everyone**
